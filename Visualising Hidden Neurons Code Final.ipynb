{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a781b3-1119-4c31-83e8-b09a43c1b620",
   "metadata": {},
   "source": [
    "**CLASSIFIER DEFINITIONS AND INITILISATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff22cb-1d6d-467b-9a66-22cc779c032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy provides arrays and useful functions for working with them\n",
    "import numpy\n",
    "# suppressing scientific notation in numpy so that numbers are mostly displayed in decimal format\n",
    "numpy.set_printoptions(suppress=True)\n",
    "\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# scipy.ndimage for rotating image arrays\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b02c4-a827-4839-a0da-3f6f8e8ba667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax function for final layer (optimal for cross-entropy loss)\n",
    "def softmax(x):\n",
    "    exp_x = numpy.exp(x - numpy.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / numpy.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76b1f1-a882-4286-8023-eaffaaf2f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU function for hidden layers\n",
    "def relu(x):\n",
    "    return numpy.where(x > 0, x, 0.0)\n",
    "\n",
    "# ReLU derivative for backprop\n",
    "def drelu(x):\n",
    "    return numpy.where(x > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57099e-45dd-4f52-9381-da1fd6e9dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function as an alternative option for hidden layers\n",
    "def sigmoid(x):\n",
    "    return scipy.special.expit(x)\n",
    "\n",
    "# sigmoid derivative for backprop\n",
    "def dsigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ccb3d6-7684-44b0-877a-0448aca01388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general derivative function\n",
    "# works for both ReLU and sigmoid, for ease of switching between the two in backpropagation\n",
    "# also includes softmax to enable optimisation for output nodes\n",
    "\n",
    "# takes in a function and an array and returns the derivative of that function applied to the array\n",
    "def deriv(fn, x):\n",
    "    if fn == relu:\n",
    "        return numpy.where(x > 0, 1.0, 0.0)\n",
    "    elif fn == softmax:\n",
    "        J0 = softmax(x).reshape(-1, 1)\n",
    "        jacobian = numpy.diagflat(J0) - numpy.dot(J0, J0.T)\n",
    "        return jacobian\n",
    "    elif fn == sigmoid:\n",
    "        return scipy.special.expit(x) * (1 - scipy.special.expit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265dc3c3-8dd7-4fa5-9759-55450cea85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN (Deep Neural Network) class for MNIST classifier\n",
    "class neuralNetwork:\n",
    "\n",
    "    # all self parameters are initialised / declared in initialisation of class\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        \n",
    "        # compiling a list of all layer node numbers for indexing later\n",
    "        self.nodes = [inputnodes] + hiddennodes + [outputnodes]\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # iterating over layers to create arrays of weights and biases with the right dimensions\n",
    "        # DNN class will automatically adapt to any number of hidden layers and nodes with this loop structure\n",
    "        # NB: usage of for loops does slow down training slightly, but only by about 5%\n",
    "        for i in range(len(self.nodes)-1):\n",
    "            \n",
    "            # using Kaiming intilisation for the weights (optimal for ReLU), i.e. normal distribution with mean 0 and stdev sqrt(2/n)\n",
    "            self.weights.append(numpy.random.normal(0.0, numpy.sqrt(2/self.nodes[i]), (self.nodes[i], self.nodes[i+1])))\n",
    "            \n",
    "            # zero vectors for biases corresponding to each layer except inputs\n",
    "            self.biases.append(numpy.zeros(self.nodes[i+1],))\n",
    "\n",
    "        # variables for loss monitoring\n",
    "        # tracker will be updated at the start of each training batch, using the current loss (with parameters from the last DNN update)\n",
    "        self.loss_tracker = 0\n",
    "        # alpha is the degree of smoothing for the exponential moving average (defined later)\n",
    "        self.alpha = 0.9999\n",
    "\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # separate activation functions for hidden and output layers\n",
    "        # usage of ReLU achieves best performance, but output should be probabilities summing to 1, which softmax does\n",
    "        self.hidden_activation = lambda x: relu(x)\n",
    "        self.output_activation = lambda x: softmax(x)\n",
    "\n",
    "        # specifying the activation functions for general deriv function\n",
    "        self.hidden_fn = relu\n",
    "        self.output_fn = softmax\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        \n",
    "        # ensuring inputs and targets for training are of the right dimension and shape (corresponding to input and final layers)\n",
    "        inputs = numpy.reshape(numpy.array(inputs_list, ndmin=2), [batch_size, self.nodes[0]])\n",
    "        targets = numpy.reshape(numpy.array(targets_list, ndmin=2), [batch_size, self.nodes[-1]])\n",
    "\n",
    "        # lists for inputs to each layer and activation function outputs\n",
    "        # image values are both the input and output for layer 0\n",
    "        layer_inputs = [inputs]\n",
    "        layer_outputs = [inputs]\n",
    "\n",
    "        # computing outputs and inputs for hidden layers\n",
    "        # minus 2 length for first and final layers\n",
    "        for i in range(len(self.nodes)-2):\n",
    "            \n",
    "            # NB: inputs are encoded as row vectors so no transposition is needed in these computations\n",
    "            h_inputs = numpy.dot(layer_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            layer_inputs.append(h_inputs.copy())\n",
    "            h_outputs = self.hidden_activation(h_inputs)\n",
    "            layer_outputs.append(h_outputs.copy())\n",
    "        \n",
    "        # final layer corresponds to last element in all lists and has a different activation, so left out of for loop above\n",
    "        final_inputs = numpy.dot(layer_outputs[-1], self.weights[-1]) + self.biases[-1] \n",
    "        final_outputs = self.output_activation(final_inputs)\n",
    "\n",
    "        # cross-entropy loss: sums output of -log of output activation for the output node corresponding to the correct label for that image\n",
    "        # approaches 0 as activation for correct output nodes approaches 1\n",
    "        # also guarantees that activation of other output nodes will be minimised since softmax returns probabilities that sum to 1\n",
    "        loss = -numpy.sum(targets * numpy.log(final_outputs)) / (self.nodes[-1] * batch_size)\n",
    "\n",
    "        # compiling a list of the gradient of each hidden layer outputs with respect to the layer inputs, for backpropagation later\n",
    "        # this is simply the derivative of the activation function applied to the layer inputs\n",
    "        self.hidden_derivs = []\n",
    "        for i in range(len(self.nodes)-2):\n",
    "            deriv_layer_output_input = deriv(self.hidden_fn, layer_inputs[i+1])\n",
    "            self.hidden_derivs.append(deriv_layer_output_input)\n",
    "\n",
    "        # linear factor from the loss calculation due to averaging over batches and output nodes, for loss gradient\n",
    "        factor = 1 / (self.nodes[-1] * batch_size)\n",
    "        \n",
    "        # initialising a list of the gradient of the loss with respect to each layer's inputs\n",
    "        # the first item is the gradient with respect to the final layer's inputs\n",
    "        # i.e., derivative of the cross-entropy loss function applied to final outputs, times derivative of softmax applied to final inputs \n",
    "        # this simplifies to final outputs minus targets\n",
    "        # due to the logarithmic and exponential nature of the softmax and cross-entropy functions respectively\n",
    "        loss_derivs = [factor * (final_outputs - targets)]\n",
    "\n",
    "        # computing the rest of the loss gradients (w.r.t. layer inputs)\n",
    "        for i in range(len(self.nodes)-2):\n",
    "            \n",
    "            # gradients are computed backwards through the DNN so each time the weights and gradient from the next layer upstream is used\n",
    "            # via chain rule, the gradient for each layer is the loss gradient of the previous (downstream) layer\n",
    "            # multiplied (dotted) with the transpose of the weights between those layers\n",
    "            # and then multiplied elementwise with the partial derivative of the hidden activation function for the (upstream) layer\n",
    "            deriv_loss_layer_input = numpy.dot(loss_derivs[0], self.weights[-1-i].T) * self.hidden_derivs[-1-i]\n",
    "\n",
    "            # adding backwards so list will be ordered ascendingly (from first to final layer), for ease of subsequent usage\n",
    "            loss_derivs.insert(0, deriv_loss_layer_input)\n",
    "\n",
    "        # finally the gradient of the loss w.r.t. the weights between each layer is\n",
    "        # the partial derivative of the loss w.r.t. the downstream layer inputs multiplied (dotted) with\n",
    "        # the transpose of the partial derivative of the downstream layer inputs w.r.t. the weights, which is the upstream layer outputs\n",
    "\n",
    "        # updating all the weights by subtracting the relevant gradient (calculated as described above) times the LR\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += self.lr * -numpy.dot(layer_outputs[i].T, loss_derivs[i])\n",
    "\n",
    "        # updates for biases are similar but averaged over the batch\n",
    "        # also the partial derivative of the the downstream layer inputs w.r.t. the biases is simply the identity matrix\n",
    "        # NB: multiplying by batch_size to 'undo' division by batch_size in the loss_derivs, since numpy.mean does this again\n",
    "        for i in range(len(self.biases)):\n",
    "            self.biases[i] += (self.lr * -numpy.mean(loss_derivs[i] * batch_size, axis=0))\n",
    "\n",
    "        # loss monitoring updates\n",
    "        # if first training run, set the loss tracker to equal the current loss\n",
    "        if self.loss_tracker == 0:\n",
    "            self.loss_tracker += loss\n",
    "            \n",
    "        # for future training runs update the loss using an exponential moving average (EMA) formula\n",
    "        # the EMA is mostly the previous average with a small adjustment for the latest loss value\n",
    "        # over multiple EMA updates the original average decays exponentially (hence the name)\n",
    "        else:\n",
    "            self.loss_tracker = self.alpha * self.loss_tracker + (1-self.alpha) * loss\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # defining a function to query the DNN, i.e. compute the DNN outputs for a given input\n",
    "    # this function is generalised to returns inputs and outputs for all layers\n",
    "    # it can be indexed in-line to select between these two and further indexed to select particular layers or even nodes\n",
    "    # all of this functionality is required for visualisation\n",
    "    def query(self, inputs_list):\n",
    "        \n",
    "        # ensuring inputs are of the right dimension and shape (corresponding to the input layer)\n",
    "        inputs = numpy.reshape(numpy.array(inputs_list, ndmin=2), [1, self.nodes[0]])\n",
    "\n",
    "        # initialising lists for layer inputs and outputs, as in the training function\n",
    "        layer_inputs = [inputs]\n",
    "        layer_outputs = [inputs]\n",
    "\n",
    "        # computing the inputs and outputs from each hidden layer (by iteration), and adding them to the lists\n",
    "        for i in range(len(self.nodes)-2):\n",
    "            h_inputs = numpy.dot(layer_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            layer_inputs.append(h_inputs.copy())\n",
    "            h_outputs = self.hidden_activation(h_inputs)\n",
    "            layer_outputs.append(h_outputs.copy())\n",
    "        \n",
    "        # computing inputs and outputs of final layer, and adding to lists\n",
    "        final_inputs = numpy.dot(layer_outputs[-1], self.weights[-1]) + self.biases[-1]\n",
    "        layer_inputs.append(final_inputs.copy())\n",
    "        final_outputs = self.output_activation(final_inputs)\n",
    "        layer_outputs.append(final_outputs.copy())\n",
    "\n",
    "        # returns a list containing two lists, which themselves each contain arrays corresponding to each layer\n",
    "        return [layer_outputs, layer_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42d6a5-78bd-4803-9c6e-b0025c7fc7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing hyperparameters, such as no. of nodes in each layer\n",
    "input_nodes = 784\n",
    "output_nodes = 10\n",
    "\n",
    "# hidden_nodes is a list to easily change number or size of layers\n",
    "hidden_nodes = [1250, 1000, 750, 500, 250, 100, 25]\n",
    "\n",
    "# initial learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# creating an instance of the DNN class with these hyperparameters\n",
    "c = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943efbdd-fcc4-45eb-a26e-5045c7658679",
   "metadata": {},
   "source": [
    "**RE-LOADING WEIGHTS AND BIASES** (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5483d8-4658-4cf2-bd47-3bd7554c8d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over the number of layers and reloading weights and biases from saved files\n",
    "# NB: this only works if the DNN c (as defined above) has the same number of layers and nodes as the saved DNN\n",
    "\n",
    "for i in range(len(c.nodes)-1):\n",
    "    c.weights[i] = numpy.loadtxt(\"/Users/benauer/Documents/DNN Saved/c_weights\" + str(i) + \"_saved.csv\", delimiter=',')\n",
    "    c.biases[i] = numpy.loadtxt(\"/Users/benauer/Documents/DNN Saved/c_biases\" + str(i) + \"_saved.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e3a8f8-c346-4225-a9de-37adbc42f05d",
   "metadata": {},
   "source": [
    "**CLASSIFIER TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62a5d0-b46c-47dd-8eab-222ab7c0d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the mnist training data CSV file into a list\n",
    "# note: the file path below should of course be replaced for a new user\n",
    "training_data_file = open(\"/Users/benauer/Downloads/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32442a28-840f-4044-bd0a-cd348fc3b2f3",
   "metadata": {},
   "source": [
    "**NB:** The following two cells (until Performance Testing) can be skipped if re-loading a saved DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf29465-3b55-42ac-bc11-4dd6b9da66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restating alpha and LR definitions here for ease of finetuning between training epochs (e.g. manual LR decay)\n",
    "c.alpha = 0.9999\n",
    "c.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ceae0-6241-41f4-8f34-0c9b0fb90b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the neural network in batches for greater efficiency and speed\n",
    "batch_size = 32\n",
    "\n",
    "# epochs is the number of times that training loops through the entire MNIST training data set\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # shuffles order of data set for each epoch\n",
    "    numpy.random.shuffle(training_data_list)\n",
    "\n",
    "    # in each epoch, training iterates over the data set in intervals equal to the batch size, with inputs and targets compiled for that batch\n",
    "    for i in range(0, len(training_data_list), batch_size):\n",
    "        batch = training_data_list[i:i+batch_size]\n",
    "\n",
    "        batch_inputs = []\n",
    "        batch_targets = []\n",
    "        \n",
    "        for record in batch:\n",
    "            # extracting numerical pixel values\n",
    "            all_values = record.split(',')\n",
    "            # scaling the inputs\n",
    "            # value range [0,1] is optimal for ReLU so no shifting required\n",
    "            inputs = numpy.asfarray(all_values[1:]) / 255.0\n",
    "            # encoding the target label as a one-hot vector with same value range [0,1]\n",
    "            targets = numpy.zeros(output_nodes)\n",
    "            # all_values[0] is the target label for this record\n",
    "            targets[int(all_values[0])] = 1\n",
    "\n",
    "            batch_inputs.append(inputs)\n",
    "            batch_targets.append(targets)\n",
    "\n",
    "        # train function automatically works via standard matrix operations with 2 dimensional inputs so no further processing is required\n",
    "        c.train(batch_inputs, batch_targets)\n",
    "\n",
    "        # loss monitoring\n",
    "        # printing the epoch number and EMA loss\n",
    "        # prints approximately 10 times per epoch\n",
    "        # by checking if the training set size divided by 10, and rounded to the nearest multiple of the batch size, divides i\n",
    "        if i % (batch_size * round(len(training_data_list) / 10 / batch_size)) == 0:\n",
    "            print(e+1,\":\", c.loss_tracker)\n",
    "\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19d1b1-d5ec-4a6b-aa9c-3b9e72f6ee74",
   "metadata": {},
   "source": [
    "**CLASSIFIER PERFORMANCE TESTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ff5b4-4be4-4858-b85a-8fab1df8fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the mnist test data CSV file into a list\n",
    "# again, the file path must be replaced for a new user\n",
    "test_data_file = open(\"/Users/benauer/downloads/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a0573-5083-44b9-b409-2373c45289b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising scorecard for the classifier's test performance\n",
    "scorecard = []\n",
    "\n",
    "# iterating once through the test data set\n",
    "for record in test_data_list:\n",
    "    # extracting numerical pixel values\n",
    "    all_values = record.split(',')\n",
    "    # the first item of each record is the correct label (integer from 0 to 9 in this case)\n",
    "    correct_label = int(all_values[0])\n",
    "    # scaling the inputs\n",
    "    # again, no shifting required\n",
    "    inputs = numpy.asfarray(all_values[1:]) / 255.0\n",
    "    # using query function to do a forward pass with each input\n",
    "    # length of the node numbers list is 1 greater than the index of the final layer\n",
    "    outputs = c.query(inputs)[0][len(c.nodes)-1]\n",
    "    # taking the index of the output node with the highest activation, i.e. the DNN's highest probability classification, or 'best guess'\n",
    "    label = numpy.argmax(outputs)\n",
    "\n",
    "    if (label == correct_label):\n",
    "        # DNN's best guess matches correct answer, so add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # DNN's best guess doesn't match correct answer, so add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a70ec2-7479-49fc-9e57-72c2e739251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the performance score, no. of correct answers divided by no. of total answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance =\", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601844fc-484d-43ac-811f-1b7ee9cd5a0c",
   "metadata": {},
   "source": [
    "**SAVING WEIGHTS AND BIASES** (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bd664-5e27-4406-8f9e-c24abcbe52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_weights_saved = c.weights.copy()\n",
    "c_biases_saved = c.biases.copy()\n",
    "\n",
    "# saving the DNN weights and biases to files in case current session is lost\n",
    "# each layer's weights and biases must be saved to a separate file since dimensions for different layers do not align\n",
    "\n",
    "# note: the file paths below are simply examples and should be replaced for each user\n",
    "\n",
    "for i in range(len(c.weights)):\n",
    "    numpy.savetxt(\"/Users/benauer/Documents/DNN Saved/c_weights\" + str(i) + \"_saved.csv\", c_weights_saved[i], delimiter=\",\")\n",
    "    numpy.savetxt(\"/Users/benauer/Documents/DNN Saved/c_biases\" + str(i) + \"_saved.csv\", c_biases_saved[i], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aaa6c2-f773-4ede-ab72-bfd3eaff75e7",
   "metadata": {},
   "source": [
    "**VISUALISATION BY OPTIMISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c135c11-b398-4adc-8ea3-b14b52925a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing matplotlib.pyplot for visual depictions of images\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# defining the grayscale cmap for ease of reference in all pyplot calls later\n",
    "gray = matplotlib.pyplot.get_cmap('gray')\n",
    "\n",
    "# creating a combined list of the MNIST test and training data for initialisation and averages later\n",
    "combined_full_data = training_data_list[:] + test_data_list[:]\n",
    "\n",
    "# storing labels separately\n",
    "combined_labels = []\n",
    "\n",
    "for i in range(len(combined_full_data)):\n",
    "    combined_labels.append(int(combined_full_data[i][0]))\n",
    "    \n",
    "    # extracting pixel values\n",
    "    image_values = combined_full_data[i][2:-1].split(',')\n",
    "    # replacing each entry in the dataset with an array of the image values excluding the label\n",
    "    combined_full_data[i] = numpy.asfarray(image_values) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6452b7-6f0b-4eec-8486-151f0f928617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for numpy.clip function later (to restrict allowed pixel values for images)\n",
    "cmin, cmax = 0, 1\n",
    "\n",
    "# derivative of numpy.clip for backpropagation in image optimisation below\n",
    "def clip_deriv(x, cmin, cmax):\n",
    "    return numpy.where((x >= cmin) & (x <= cmax), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7793d4-8a36-44d8-bb1d-18dc0592eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_grad_layer(DNN, img, tlayer):\n",
    "    '''\n",
    "    This function computes the gradient of the activation of (all nodes in) a target layer in a specified classifier DNN with respect to an\n",
    "    image input, by backpropagating the layer activation through the previous (upstream) layers of the DNN.\n",
    "    It takes as input a DNN, an image in a [1,784] array format, and the number of the target layer (as an integer).\n",
    "    It returns the gradient as another [1,784] array.\n",
    "    '''\n",
    "\n",
    "    # querying the DNN once and gathering the resulting data for maximum efficiency\n",
    "    forward_pass = DNN.query(img)\n",
    "    layer_inputs = forward_pass[1]\n",
    "    layer_outputs = forward_pass[0]\n",
    "\n",
    "    # firstly the partial derivatives of each layer's outputs with respect to it's inputs are computed\n",
    "    # this is simply the derivative of the hidden activation function (e.g. ReLU) applied to the layer inputs\n",
    "    hidden_derivs = []\n",
    "    for i in range(len(DNN.nodes)-2):\n",
    "        deriv_layer_output_input = deriv(DNN.hidden_fn, layer_inputs[i+1])\n",
    "        hidden_derivs.append(deriv_layer_output_input)\n",
    "\n",
    "    # next the partial derivatives of the tlayer activation w.r.t. the input to each layer are computed, moving backwards through the layers\n",
    "    # the final partial derivative following this pattern will be for the activation w.r.t. the input image which is the desired output\n",
    "    \n",
    "    # if the target layer is a hidden layer then all the partial derivatives use only the hidden function\n",
    "    if tlayer < len(DNN.nodes)-1:\n",
    "        \n",
    "        # the first partial derivative w.r.t. tlayer inputs is simply the hidden_derivs item for the target layer, since the activations are\n",
    "        # the tlayer outputs (item tlayer-1 since there is no entry for layer 0 in the hidden_derivs list)\n",
    "        \n",
    "        activation_derivs = [hidden_derivs[tlayer-1]]\n",
    "\n",
    "    # calculations will be done a similar way when targeting the output layer but with the output function for the first partial derivative\n",
    "    elif tlayer == len(DNN.nodes)-1:\n",
    "\n",
    "        # NB: the output function SoftMax depends on all inputs to the output layer for any individual output activation\n",
    "        # hence the derivative returns a [10,10] matrix, where each row is the gradient of a particular output node's activation\n",
    "        # the intention is to combine the effects of these derivatives anyway (from all the non-target nodes)\n",
    "        # so the matrix can be summed along the rows here, which is equivalent to summing after backpropagation but more efficient\n",
    "        \n",
    "        activation_derivs = [numpy.sum(deriv(DNN.output_fn, layer_inputs[tlayer]), axis=0)]\n",
    "\n",
    "    # if tlayer is the 1st hidden layer, there are no more hidden layer gradients to be computed (only gradient w.r.t. inputs)\n",
    "    if tlayer != 1:\n",
    "\n",
    "        # computing gradients for the rest of the hidden layers until the first hidden layer\n",
    "\n",
    "        # the partial derivative w.r.t. the inputs of each layer tlayer-1-j is the first partial derivative from above (w.r.t. tlayer)\n",
    "        # multiplied (dotted) with the transpose of the tlayer-1-j weights and multiplied elementwise with the\n",
    "        # partial derivative of the outputs of tlayer-1-j w.r.t. its inputs (item tlayer-2 in hidden_derivs list)\n",
    "        for j in range(tlayer-1):\n",
    "            deriv_act_layer_input = numpy.dot(activation_derivs[0], DNN.weights[tlayer-1-j].T) * hidden_derivs[tlayer-2-j]\n",
    "            \n",
    "            activation_derivs.insert(0, deriv_act_layer_input)\n",
    "\n",
    "    # gradient w.r.t. the first hidden layer inputs is now element 0 of activation_derivs\n",
    "    # to get the gradient w.r.t. the image this simply needs to be multiplied (dotted) with the weights between layer 0 and 1\n",
    "    # since layer 0 (the image values) has no activation function\n",
    "    act_deriv_image = numpy.dot(activation_derivs[0], DNN.weights[0].T)\n",
    "\n",
    "    return act_deriv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47973be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_grad_node(DNN, img, tlayer, tnode):\n",
    "    '''\n",
    "    This function is very similar to act_grad_layer but it computes the gradient of the activation of a particular node in a target layer\n",
    "    w.r.t. the image input, as opposed to the gradient of the activations of the entire layer.\n",
    "\n",
    "    Again, it takes a DNN, an image array, and a target layer number as input, but also the target node number.\n",
    "    It returns the gradient as another [1,784] array.\n",
    "\n",
    "    Both functions are used below to optimise an image for exclusive activation of a target node in a layer (for visualisation).\n",
    "    '''\n",
    "\n",
    "    # gathering DNN query data\n",
    "    forward_pass = DNN.query(img)\n",
    "    layer_inputs = forward_pass[1]\n",
    "    layer_outputs = forward_pass[0]\n",
    "\n",
    "    # computing partial derivatives of each layers outputs w.r.t. inputs again\n",
    "    hidden_derivs = []\n",
    "    for i in range(len(DNN.nodes)-2):\n",
    "        deriv_layer_output_input = deriv(DNN.hidden_fn, layer_inputs[i+1])\n",
    "        hidden_derivs.append(deriv_layer_output_input)\n",
    "\n",
    "    # the 'layer inputs' to the ith node (a scalar) depends on the ith column only of the weights from the previous layer\n",
    "    DNN_weights_to_node = DNN.weights[tlayer-1][:, [tnode]]\n",
    "    inputs_to_node = numpy.dot(layer_outputs[tlayer-1], DNN_weights_to_node) + DNN.biases[tlayer-1][tnode]\n",
    "\n",
    "    # backpropagating through DNN to compute partial derivatives of tnode activation w.r.t. the inputs to each layer\n",
    "    # separating hidden and output target layers again for the same reason\n",
    "    if tlayer < len(DNN.nodes)-1:\n",
    "        \n",
    "        # the first partial derivative w.r.t. tnode inputs is calculated from inputs_to_node so must be separate from hidden_derivs\n",
    "        # list which is based on entire layers\n",
    "        activation_derivs = [deriv(DNN.hidden_fn, inputs_to_node)]\n",
    "\n",
    "        # multiplying first partial derivative w.r.t. tlayer-1 inputs\n",
    "        # when looking at the tnode specifically this part of the gradient is different for the hidden and output layers\n",
    "        # so this item cannot be incorporated into the general 'for loop' below\n",
    "        # this step should also be skipped if the target layer is the 1st hidden layer, as in the previous function\n",
    "        if tlayer != 1:\n",
    "            activation_derivs.insert(0, numpy.dot(activation_derivs[0], DNN_weights_to_node.T) * hidden_derivs[tlayer-1-1])\n",
    "\n",
    "    # recall the SoftMax derivative returns a [10,10] matrix\n",
    "    # the relevant row of this matrix ([1,10]) must be indexed for the partial derivative of the target node activation\n",
    "    elif tlayer == len(DNN.nodes)-1:\n",
    "        activation_derivs = [deriv(DNN.output_fn, layer_inputs[tlayer])[tnode, :]]\n",
    "\n",
    "        # first partial derivative from above is already [1,10], so it is multiplied by the entire weights from tlayer-1 (transposed)\n",
    "        # as opposed to just the weights to that node (when targeting hidden layers)\n",
    "        activation_derivs.insert(0, numpy.dot(activation_derivs[0], DNN.weights[tlayer-1].T) * hidden_derivs[tlayer-1-1])\n",
    "\n",
    "    # again, skipping the for loop if tlayer is the 1st hidden layer\n",
    "    if tlayer != 1:\n",
    "\n",
    "        # computing gradients for the rest of the hidden layers\n",
    "        for j in range(tlayer-2):\n",
    "            deriv_act_layer_input = numpy.dot(activation_derivs[0], DNN.weights[tlayer-2-j].T) * hidden_derivs[tlayer-3-j]\n",
    "            \n",
    "            activation_derivs.insert(0, deriv_act_layer_input)\n",
    "\n",
    "        # again, gradient w.r.t. the image is now simply element 0 of activation_derivs times the weights for layer 0\n",
    "        act_deriv_image = numpy.dot(activation_derivs[0], DNN.weights[0].T)\n",
    "\n",
    "    # if tlayer is the 1st hidden layer, the partial derivative w.r.t. to the layer inputs is a scalar ([1,1]) so must be multiplied (dotted)\n",
    "    # with the row vector (transposed) DNN_weights_to_node.T, which is [1,784]\n",
    "    elif tlayer == 1:\n",
    "        act_deriv_image = numpy.dot(activation_derivs[0], DNN_weights_to_node.T)\n",
    "\n",
    "    return act_deriv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb910e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a new class for visualising the nodes of a classifier DNN\n",
    "class visualisation:\n",
    "\n",
    "    # the image is first initialised, with all self parameters declared\n",
    "    def __init__(self, initialisation):\n",
    "\n",
    "        # there are three options for the choice of initialisation, two of which are specified as strings\n",
    "        if type(initialisation) == str:\n",
    "            # 'zero' starts at near-zero values for all pixels (not completely zero to avoid any vanishing gradient problems)\n",
    "            if initialisation == 'zero':\n",
    "                self.values = numpy.zeros([1,784]) + 0.01\n",
    "            # 'random' samples pixel values from a normal distribution with mean 0.5 and standard deviation 0.1\n",
    "            # this keeps pixels more or less entirely within the range 0 to 1\n",
    "            elif initialisation == 'random':\n",
    "                self.values = numpy.random.normal(0.5, 0.1, [1,784])\n",
    "\n",
    "        # the third option simply initialises from a specified image, which is reshaped if necessary\n",
    "        else:\n",
    "            self.values = numpy.reshape(initialisation.copy(), [1,784])\n",
    "\n",
    "        # defining variables for monitoring training\n",
    "        \n",
    "        # these will be updated with the latest activation values for the target node and other nodes respectively\n",
    "        # using an exponential moving average (EMA) formula (see below)\n",
    "        \n",
    "        # these measures are stored and displayed separately for more fine-grained information about the image during optimisation\n",
    "        # as opposed to in a combined 'loss function'\n",
    "        self.t_activation_ema = 0\n",
    "        self.o_activation_ema = 0\n",
    "        self.tvreg_ema = 0\n",
    "        self.l1reg_ema = 0\n",
    "        self.second_max_ema = 0\n",
    "\n",
    "        self.loss_ema = 0\n",
    "\n",
    "        # smoothing parameter for the EMA formula (default value here)\n",
    "        self.alpha = 0.9\n",
    "\n",
    "        pass\n",
    "\n",
    "    def train(self, DNN, tlayer, tnode, learningrate, penaltyO, TVweight, L1weight):\n",
    "        '''\n",
    "        This function optimises / 'trains' the image for activation of a target node in a target layer of a specified DNN, by backpropagation\n",
    "        using the act_grad_node function.\n",
    "        \n",
    "        It takes as input a DNN, the numbers of the target layer and node, and several parameters relating to the optimisation process itself,\n",
    "        specifically:\n",
    "        learningrate: The learning rate\n",
    "        penaltyO: The weighting applied to penalise activations of non-target (Other) nodes in the target layer\n",
    "        TVweight: The weighting applied to TV regularisation during optimisation\n",
    "        L1weight: The weighting applied to L1 regularisation during optimisation\n",
    "\n",
    "        Note that a numpy.clip 'activation function' is applied to the image at the start of each optimisation step, and this is used to\n",
    "        measure activations and all other regularisation quantities.\n",
    "        \n",
    "        The function then updates the (raw / non-activated) values of the image (self.values) based on the gradients from act_grad_node and\n",
    "        derivatives of the other functions used (for activation and regularisation), before being called again for the next optimisation step.\n",
    "        '''\n",
    "\n",
    "        # firstly all metrics for the current image are calculated\n",
    "        \n",
    "        # limiting pixel values in the image to the range specified above\n",
    "        # normally 0 to 1 since this is the same range as the normalised MNIST images used to train and test the classifier\n",
    "        clip_values = numpy.clip(self.values, cmin, cmax)\n",
    "        \n",
    "        # gathering data from forward pass immediately for efficiency\n",
    "        # only layer outputs needed since act_grad_node function handles layer inputs\n",
    "        layer_outputs = DNN.query(clip_values)[0]\n",
    "\n",
    "        # extracting target node activation, the primary indicator of optimisation success\n",
    "        tnode_activation = layer_outputs[tlayer][0][tnode]\n",
    "\n",
    "        # taking the mean of the activations of all other nodes (hence tnode_activation is subtracted from the sum)\n",
    "        # the layer outputs are from ReLU or sigmoid so there is no risk of negative and positive values cancelling each other out\n",
    "        other_activations = (numpy.sum(layer_outputs[tlayer]) - tnode_activation) / (DNN.nodes[tlayer] - 1)\n",
    "\n",
    "        # the activation of the second-most activated node after the target node can be used instead of the mean activation of other nodes\n",
    "        # as an indicator of the success of optimisation for the target node (relative to other nodes)\n",
    "        if numpy.argmax(layer_outputs[tlayer][0]) == tnode:\n",
    "            second_max_idx = numpy.argsort(layer_outputs[tlayer][0])[-2]\n",
    "            second_max = layer_outputs[tlayer][0][second_max_idx]\n",
    "\n",
    "        # if tnode does not have the maximum activation then the 'second_max' is actually just the first maximum\n",
    "        else:\n",
    "            second_max_idx = numpy.argmax(layer_outputs[tlayer][0])\n",
    "            second_max = layer_outputs[tlayer][0][second_max_idx]\n",
    "\n",
    "        # L1 regularisation measures the sum of the absolute values of all pixels to discourage unnecessary and/or extreme pixel values\n",
    "        l1_regularisation = numpy.sum(numpy.abs(clip_values))\n",
    "        \n",
    "        # TV regularisation measures the difference between versions of the image translated 1 pixel each way on both the vertical and\n",
    "        # horizontal axes, which is most easily done with the image in a [28,28] format\n",
    "        image = numpy.reshape(clip_values, [28,28])\n",
    "        tv_regularisation = numpy.sum(numpy.abs(image[1:,:] - image[:-1,:])) + numpy.sum(numpy.abs(image[:,1:] - image[:,:-1]))\n",
    "\n",
    "        # the loss corresponds to the success of optimisation w.r.t. all measures in combination\n",
    "        # this includes the regularisation measures, weighted as in the gradients below\n",
    "        # the loss does not affect optimisation itself but can be an informative metric to monitor\n",
    "        loss = -(tnode_activation - penaltyO * other_activations - TVweight * tv_regularisation - L1weight * l1_regularisation)\n",
    "        \n",
    "        # next, backpropagation is conducted\n",
    "\n",
    "        # tgrad is the gradient of the target node activation w.r.t. the original unclipped image values\n",
    "        # this is the tnode activation gradient w.r.t. the clipped image times the derivative of numpy.clip applied to the original values\n",
    "        tgrad = act_grad_node(DNN, clip_values, tlayer, tnode) * clip_deriv(self.values, cmin, cmax)\n",
    "\n",
    "        # ograd is used to optimise against activation of other nodes in the target layer\n",
    "        ograd = (act_grad_layer(DNN, clip_values, tlayer) * clip_deriv(self.values, cmin, cmax) - tgrad) / (DNN.nodes[tlayer] - 1)\n",
    "\n",
    "        # NB: clip_deriv is deliberately not included in the L1 and TV gradients to prevent clip from 'killing' certain pixels permanently\n",
    "        # i.e. clip_deriv would normally cause the gradients of clipped pixels (outside the bounds) to become 0 thereafter\n",
    "        # which would 'trap' these pixels at the bounds and create very sharp images, appearing unregularised\n",
    "        \n",
    "        # but with this method TV or L1 regularisation can keep these pixels dynamic, when that is beneficial for regularisation\n",
    "        # also note clip_deriv is simply 1 within the bounds so there are no other effects of removing it\n",
    "\n",
    "        # l1_grad is the gradient of the L1 quantity w.r.t. the clipped values\n",
    "        l1_grad = numpy.sign(clip_values)\n",
    "\n",
    "        # tv_grad is the gradient of the TV quantity w.r.t. the clipped values\n",
    "        # the image is padded by 1 pixel first to enable efficient comparison of neighbouring pixels for tv_grad (in one line below)\n",
    "        padded = numpy.pad(image, pad_width=1)\n",
    "        tv_grad = (numpy.sign(image - padded[:-2, 1:-1]) + numpy.sign(image - padded[2:, 1:-1]) + numpy.sign(image - padded[1:-1, :-2]) + numpy.sign(image - padded[1:-1, 2:]))\n",
    "        \n",
    "        # again, TV computations are done with a [28,28] image so this needs to be reshaped before incorporation with the other gradients\n",
    "        tv_grad_reshaped = numpy.reshape(tv_grad, [1,784])\n",
    "\n",
    "        # the unclipped image values are then updated based on the learning rate, and all the gradients, and their respective weightings\n",
    "        # this is essentially minus the gradient of the loss w.r.t. the image times the learning rate\n",
    "        self.values += learningrate * (tgrad - penaltyO * ograd - TVweight * tv_grad_reshaped - L1weight * l1_grad)\n",
    "\n",
    "        # finally, the relevant training quantities (and the loss) are monitored\n",
    "\n",
    "        # on the first optimisation step, each quantity is simply set to its current value to avoid starting the EMA from 0\n",
    "        if self.t_activation_ema == 0:\n",
    "            self.t_activation_ema += tnode_activation\n",
    "            self.o_activation_ema += other_activations\n",
    "            self.tvreg_ema += tv_regularisation\n",
    "            self.l1reg_ema += l1_regularisation\n",
    "            self.second_max_ema += second_max\n",
    "            \n",
    "            self.loss_ema += loss\n",
    "\n",
    "        # in future steps, the EMAs are updated according to the EMA formula with the same alpha value\n",
    "        # as in DNN training, the alpha value determines the degree of average smoothing\n",
    "        # i.e., how much the EMA is influenced by the new value for each quantity\n",
    "        else:\n",
    "            self.t_activation_ema = self.alpha * self.t_activation_ema + (1-self.alpha) * tnode_activation\n",
    "            self.o_activation_ema = self.alpha * self.o_activation_ema + (1-self.alpha) * other_activations\n",
    "            self.tvreg_ema = self.alpha * self.tvreg_ema + (1-self.alpha) * tv_regularisation\n",
    "            self.l1reg_ema = self.alpha * self.l1reg_ema + (1-self.alpha) * l1_regularisation\n",
    "            self.second_max_ema = self.alpha * self.second_max_ema + (1-self.alpha) * second_max\n",
    "            \n",
    "            self.loss_ema = self.alpha * self.loss_ema + (1-self.alpha) * loss\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac6a01-e9b0-4a63-97a3-93673db80a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising an image for optimisation\n",
    "# near-zero values is the default, but random values can also be used or an MNIST image from combined_full_data\n",
    "v = visualisation('zero')\n",
    "\n",
    "# setting targets for optimisation\n",
    "DNN = c\n",
    "target_layer = 7\n",
    "target_node = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f5324-b7a8-4ac8-b8fa-34af89715d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restating hyper-parameters for ease of fine-tuning\n",
    "# these will be input into the train function below\n",
    "learningrate = 0.1\n",
    "TVweight = 0.256\n",
    "L1weight = 0.0256\n",
    "# penalty term for other activations is usually kept at 0 but can be adjusted for experimental purposes\n",
    "penaltyO = 0\n",
    "\n",
    "# fine-tuning alpha for the EMA formulas\n",
    "# a low value such as 0.9, or even 0, is normally sufficient, since optimisation is quite rapid unless the LR is very small\n",
    "v.alpha = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea152a-8bf9-48ce-a849-8bf6b1fbbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps is the number of times that the train function will be called and the image values will be updated\n",
    "steps = 30\n",
    "\n",
    "# note: it is also straightforward to nest this training loop within other loops to optimise many images consecutively\n",
    "\n",
    "for s in range(steps):\n",
    "\n",
    "    # train is called using the values defined in the previous cell\n",
    "    v.train(c, target_layer, target_node, learningrate, penaltyO, TVweight, L1weight)\n",
    "\n",
    "    # every 10 steps, the current step number is printed next to (the EMA of) all the tracked quantities\n",
    "    # these are also printed at the start and end of optimisation\n",
    "    if (s % 10 == 0) or (s == 0) or (s == steps-1):\n",
    "        \n",
    "        # the first line below displays the mean activation of other nodes in tlayer\n",
    "        # while the second line (the default) displays only the highest other activation\n",
    "        # these can be selected between\n",
    "        \n",
    "        #print(str(s),\":\", f\"{v.t_activation_ema:.6f}\", f\"{v.o_activation_ema:.6f}\", f\"{v.tvreg_ema:.6f}\", f\"{v.l1reg_ema:.6f}\", f\"{v.loss_ema:.6f}\")\n",
    "        print(str(s),\":\", f\"{v.t_activation_ema:.6f}\", f\"{v.second_max_ema:.6f}\", f\"{v.tvreg_ema:.6f}\", f\"{v.l1reg_ema:.6f}\", f\"{v.loss_ema:.6f}\")\n",
    "\n",
    "    # if 50 steps are completed without the target node activation increasing beyond 0\n",
    "    # the node is most likely 'dead', meaning it does not respond to any input images\n",
    "    # this threshold can be manually adjusted here of course\n",
    "    if s == 50:\n",
    "        if v.t_activation_ema == 0:\n",
    "            print(\"Dead node.\")\n",
    "            break\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4eaa8e-53da-400a-ac9b-148d57732745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the values into a [28,28] image format\n",
    "vif = numpy.reshape(numpy.clip(v.values,0,1), [28,28])\n",
    "\n",
    "# displaying the image\n",
    "matplotlib.pyplot.imshow(vif, cmap = gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8826b4-0c59-405e-89cf-a8b78a997a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# querying the network for the activations induced by the optimised image in the target layer and the output layer\n",
    "\n",
    "# temporarily setting numpy to print all array values rather than an abbreviated version with ellipses\n",
    "with numpy.printoptions(threshold=numpy.inf):\n",
    "    print(c.query(numpy.clip(v.values,0,1))[0][target_layer][0])\n",
    "\n",
    "    # reshaping output activations to display them horizontally\n",
    "    print(numpy.reshape(c.query(numpy.clip(v.values,0,1))[0][-1][0], [10,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756fa84-3dd4-4143-8906-b0c901c22f3d",
   "metadata": {},
   "source": [
    "**SAVING IMAGES** (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36223fa-db02-4b00-bf67-30f232a18e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the (reshaped) image values, target layer activations and output activations\n",
    "f_img = numpy.reshape(numpy.clip(v.values, 0, 1), [28,28])\n",
    "f_tlayer_activations = c.query(numpy.clip(v.values, 0, 1))[0][target_layer][0]\n",
    "f_output_activations = c.query(numpy.clip(v.values, 0, 1))[0][-1][0]\n",
    "\n",
    "# note: the following file paths are simply examples and should be replaced\n",
    "# of course the final values from training can also be referenced in the file names\n",
    "\n",
    "fimg_file = \"/Users/benauer/Documents/Example Folder/Example Image.png\"\n",
    "fvalues_file = \"/Users/benauer/Documents/Example Folder/Example Image Values.csv\"\n",
    "factivations_file = \"/Users/benauer/Documents/Example Folder/Example TLayer Activations.csv\"\n",
    "foutput_file = \"/Users/benauer/Documents/Example Folder/Example Output Activations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48145284-a18e-4bc7-a2ae-fbab3daeee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the settings for the saved image\n",
    "# these settings save the image at a desired size without any distortion or modifications\n",
    "\n",
    "# the figure is initially given a size in inches with no frame\n",
    "# by default the size is 1x1 inches but can be adjusted\n",
    "# this is later multiplied by the DPI 28 so in_size determines the eventual size in pixels as a multiple of 28x28\n",
    "in_size = 1\n",
    "fig = matplotlib.pyplot.figure(figsize=(in_size,in_size), frameon=False)\n",
    "\n",
    "# ensuring the image fills the entire space in the saved image (including by disabling the display of axes)\n",
    "ax = matplotlib.pyplot.Axes(fig, [0, 0, 1, 1])\n",
    "ax.set_axis_off()\n",
    "fig.add_axes(ax)\n",
    "\n",
    "# defining the image as monochrome gray with no interpolation to prevent blurring of pixels if scaling up\n",
    "ax.imshow(f_img, cmap = gray, interpolation='none')\n",
    "\n",
    "# saving the open figure fig, with DPI 28, meaning the final dimensions are DPI * in_size pixels\n",
    "matplotlib.pyplot.savefig(fimg_file, dpi=28, pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfbfc6-8190-438a-a36a-568ca7f126d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the values to their respective files\n",
    "# this is very straightforward with numpy using savetxt (and loadtxt later)\n",
    "# activations are stored to 10 decimal places while pixel values are stored with maximum precision\n",
    "# all values are separated by commas\n",
    "\n",
    "numpy.savetxt(fvalues_file, numpy.clip(v.values,0,1), delimiter=\",\")\n",
    "numpy.savetxt(factivations_file, f_tlayer_activations, fmt='%.10f', delimiter=\",\")\n",
    "numpy.savetxt(foutput_file, f_output_activations, fmt='%.10f', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eff000-e361-407f-928a-c97383445fa6",
   "metadata": {},
   "source": [
    "**LOADING IMAGES** (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e12cb7-5025-4ba3-a66c-3592fa9a83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_file should be replaced with any CSV containing the full array values of the image to be loaded\n",
    "example_file = \"/Users/benauer/Documents/TV + L1 Examples/Layer 7; TV 0.25; L1 0.025!/1; 30 steps; 21.524354 act.csv\"\n",
    "\n",
    "# a numpy array is then defined with these values and displayed to verify whether the image has been loaded correctly\n",
    "loaded_image = numpy.loadtxt(example_file, delimiter=',')\n",
    "loaded_reshaped = numpy.reshape(loaded_image, [28,28])\n",
    "matplotlib.pyplot.imshow(loaded_reshaped, cmap = gray)\n",
    "\n",
    "# once loaded the image can be re-used for various purposes, e.g. to query the DNN again or for further optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721bf48-8718-43ce-b4f1-335205be9021",
   "metadata": {},
   "source": [
    "**AVERAGE IMAGE GENERATOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceafb01-db47-41d1-af5a-d8a1b91c3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising a list of 1x784 zero vectors corresponding to each digit\n",
    "avg_imgs = [numpy.zeros([1,784])] * 9\n",
    "\n",
    "# NB: this loop can take many minutes to run to completion\n",
    "\n",
    "for onode in range(c.nodes[-1]):\n",
    "    amount = 0\n",
    "\n",
    "    # looping through combined_full_data for each output node and adding relevant image values to that vector\n",
    "    for i in range(len(combined_full_data)):\n",
    "\n",
    "        # the threshold for adding images is 0.9 activation by default but can be decreased or increased\n",
    "        if c.query(combined_full_data[i])[0][-1][0][onode] > 0.9:\n",
    "            avg_imgs[onode] += combined_full_data[i]\n",
    "            amount += 1\n",
    "\n",
    "        # print statements report progress through each digit as a percentage\n",
    "        if i % (len(combined_full_data) / 100) == 0:\n",
    "            print(str(onode), \": \", f\"{100 * i / len(combined_full_data):.0f}\", \"%\")\n",
    "\n",
    "    # average image is divided by the number of images that were added to normalise values\n",
    "    avg_imgs[onode] = avg_imgs[onode] / amount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
